<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>üî• High CPU usage on faulty endpoint | dcebotarenco</title><meta name=keywords content><meta name=description content="üßë‚Äçüéì tltr Infinite while loop was causing the issue. Write unit tests. Test the exit condition of your while loops.
üêõ Issue We had some kind of serious performance issue on production. The CPU periodically was pegged at 100% and stayed that way until we restarted the Tomcat. It was degrading the overall site performance for quite a while. We had two instances with peak similarly in CPU. Seems like it must be something inside the Tomcat since that&rsquo;s what is eating the CPU."><meta name=author content="dcebotarenco"><link rel=canonical href=https://dcebotarenco.github.io/posts/high-cpu-usage-while-loop/><meta name=google-site-verification content="XYZabc"><meta name=yandex-verification content="XYZabc"><meta name=msvalidate.01 content="XYZabc"><link crossorigin=anonymous href=/assets/css/stylesheet.5f6fc70b4df6e6744f60b0eae79a1f4a64b2337390cb4a99d81e8157dc1b54a0.css integrity="sha256-X2/HC0325nRPYLDq55ofSmSyM3OQy0qZ2B6BV9wbVKA=" rel="preload stylesheet" as=style><script defer crossorigin=anonymous src=/assets/js/highlight.f413e19d0714851f6474e7ee9632408e58ac146fbdbe62747134bea2fa3415e0.js integrity="sha256-9BPhnQcUhR9kdOfuljJAjlisFG+9vmJ0cTS+ovo0FeA=" onload=hljs.initHighlightingOnLoad()></script>
<link rel=icon href=https://dcebotarenco.github.io/icon.png><link rel=icon type=image/png sizes=16x16 href=https://dcebotarenco.github.io/icon.png><link rel=icon type=image/png sizes=32x32 href=https://dcebotarenco.github.io/icon.png><link rel=apple-touch-icon href=https://dcebotarenco.github.io/icon.png><link rel=mask-icon href=https://dcebotarenco.github.io/icon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script type=application/javascript>var doNotTrack=!1;doNotTrack||(function(e,t,n,s,o,i,a){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,i=t.createElement(n),a=t.getElementsByTagName(n)[0],i.async=1,i.src=s,a.parentNode.insertBefore(i,a)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-123-45","auto"),ga("send","pageview"))</script><meta property="og:title" content="üî• High CPU usage on faulty endpoint"><meta property="og:description" content="üßë‚Äçüéì tltr Infinite while loop was causing the issue. Write unit tests. Test the exit condition of your while loops.
üêõ Issue We had some kind of serious performance issue on production. The CPU periodically was pegged at 100% and stayed that way until we restarted the Tomcat. It was degrading the overall site performance for quite a while. We had two instances with peak similarly in CPU. Seems like it must be something inside the Tomcat since that&rsquo;s what is eating the CPU."><meta property="og:type" content="article"><meta property="og:url" content="https://dcebotarenco.github.io/posts/high-cpu-usage-while-loop/"><meta property="og:image" content="https://dcebotarenco.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-07-01T17:02:01+03:00"><meta property="article:modified_time" content="2022-07-01T17:02:01+03:00"><meta property="og:site_name" content="dcebotarenco"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://dcebotarenco.github.io/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"><meta name=twitter:title content="üî• High CPU usage on faulty endpoint"><meta name=twitter:description content="üßë‚Äçüéì tltr Infinite while loop was causing the issue. Write unit tests. Test the exit condition of your while loops.
üêõ Issue We had some kind of serious performance issue on production. The CPU periodically was pegged at 100% and stayed that way until we restarted the Tomcat. It was degrading the overall site performance for quite a while. We had two instances with peak similarly in CPU. Seems like it must be something inside the Tomcat since that&rsquo;s what is eating the CPU."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://dcebotarenco.github.io/posts/"},{"@type":"ListItem","position":2,"name":"üî• High CPU usage on faulty endpoint","item":"https://dcebotarenco.github.io/posts/high-cpu-usage-while-loop/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"üî• High CPU usage on faulty endpoint","name":"üî• High CPU usage on faulty endpoint","description":"üßë‚Äçüéì tltr Infinite while loop was causing the issue. Write unit tests. Test the exit condition of your while loops.\nüêõ Issue We had some kind of serious performance issue on production. The CPU periodically was pegged at 100% and stayed that way until we restarted the Tomcat. It was degrading the overall site performance for quite a while. We had two instances with peak similarly in CPU. Seems like it must be something inside the Tomcat since that\u0026rsquo;s what is eating the CPU.","keywords":[],"articleBody":"üßë‚Äçüéì tltr Infinite while loop was causing the issue. Write unit tests. Test the exit condition of your while loops.\nüêõ Issue We had some kind of serious performance issue on production. The CPU periodically was pegged at 100% and stayed that way until we restarted the Tomcat. It was degrading the overall site performance for quite a while. We had two instances with peak similarly in CPU. Seems like it must be something inside the Tomcat since that‚Äôs what is eating the CPU.\nHere is the 6-week view: Here is the 12-week view: The immediate fall of the CPU is where we restart the Tomcat. As you see, after the restart, the CPU jumps back on the ladder ü™ú in a couple of days.\nüïµÔ∏è‚Äç‚ôÇÔ∏è Investigation 1. Thread dump \u0026 top -H On Linux, the top -h is useful to determine the overall usage by all processes and break it down to certain threads within a process. Our PID: Run kill 3 on the main PID that‚Äôs consuming a lot of CPU. This will give you the thread dump. It does not stop the running process, but it stops the world inside the JVM.\nWhat we see is 596 of CPU%. This is related to the number of cores attached to the machine. One core is 100% Convert the PID from top -H from decimal to hex and match it with the nid from the thread dump.\n6458 -\u003e nid=0x1936 Not the ideal way to monitor a JVM instance. You should prefer agents like Sematext, JProfiler, YourKit or JFR. But we have what we have üëâ\n\"http-nio-8080-exec-127\" #328 daemon prio=5 os_prio=0 tid=0x00007f9f20020000 lwp=6454 nid=0x1936 runnable [0x00007f9e4ada4000] java.lang.Thread.State: RUNNABLE at java.util.HashMap.hash(HashMap.java:339) at java.util.HashMap.put(HashMap.java:612) at java.util.HashSet.add(HashSet.java:220) at java_util_Set$add$0.call(Unknown Source) at com.site.api.Controller.method(Controller.groovy:95) at com.site.api.Controller.method(Controller.groovy) \"http-nio-8080-exec-156\" #39893 daemon prio=5 os_prio=0 tid=0x00007f9f20024000 lwp=18378 nid=0x47ca runnable [0x00007f9e3199e000] java.lang.Thread.State: RUNNABLE at java.util.HashMap.hash(HashMap.java:339) at java.util.HashMap.put(HashMap.java:612) at java.util.HashSet.add(HashSet.java:220) at java_util_Set$add$0.call(Unknown Source) at com.site.api.Controller.method(Controller.groovy:95) at com.site.api.Controller.method(Controller.groovy) \"http-nio-8080-exec-95\" #203 daemon prio=5 os_prio=0 tid=0x00007f9f200a9000 lwp=5605 nid=0x15e5 runnable [0x00007f9e48d82000] java.lang.Thread.State: RUNNABLE at com.site.api.Controller.method(Controller.groovy:95) at com.site.api.Controller.method(Controller.groovy) at com.site.api.Controller$$FastClassBySpringCGLIB$$8fdc140f.invoke() at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:752) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) \"http-nio-8080-exec-120\" #321 daemon prio=5 os_prio=0 tid=0x00007f9f20036800 lwp=6351 nid=0x18cf runnable [0x00007f9e4cec3000] java.lang.Thread.State: RUNNABLE at java_util_Set$add$0.call(Unknown Source) at com.site.api.Controller.method(Controller.groovy:95) at com.site.api.Controller.method(Controller.groovy) at com.site.api.Controller$$FastClassBySpringCGLIB$$8fdc140f.invoke() at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:752) 2. Traffic I analyzed the traffic at the point of time where the CPU jumps. I got some httpd logs. httpd is in front of Tomcat for PerimeterX compatibility. Example of logs:\n87.250.224.200 - - [06/Jun/2022:21:17:08 +0000] \"GET /the-faulty-endpoint/id-1 HTTP/1.1\" 502 341 \"https://www.site.com/pages/page-1\" \"Mozilla/5.0 (compatible; YandexBot/3.0; +http://yandex.com/bots) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.268\" 120120565 85.45.207.139 - - [06/Jun/2022:21:18:08 +0000] \"GET /the-faulty-endpoint/id-2 HTTP/1.1\" 502 341 \"https://www.site.com/pages/page-1\" \"Mozilla/5.0 (compatible; YandexBot/3.0; +http://yandex.com/bots) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.268\" 120122901 At that point in point in time, I saw just a lot of bots (Apple, Google, Yandex, Bing) indexing the pages\n‚úÖ Put things together What we have now is the requests which tell us the URLs that are called and the values in a URLs. The values in the paths are different id-1, id-2, id-n. We also have the code, which we can analyze locally. Code has no tests üòí\nSimplified pseudo-code:\nint rowsInDB = findBy('id-from-url'); int buffer = 10; int minRows = Math.min(rowsInDB, rowsInDB + 10); Set randomIndexes = []; while (randomIndexes.size() \u003c buffer) { randomIndexes.add(random.nextInt(minRows)); } At first, I could not spot the bug because I was on the local environment with no data in my H2 database.\nI assembled a list of all the requests within CPU increase timeframe into a CSV file. Launched locally the JMeter, VisualVM, JDK Mission Control and the app connected to the QA database with data and fired all the requests to my local instance. Finally, I noticed locally a CPU increase, which is not going down.\nThere was an id that returned 5 rows from the database. Then I realized that the problem is related to the random.nextInt(minRows) and the Set collection. Here is why:\nint rowsInDB = findBy('faulty-id'); //returns 5 int buffer = 10; int minRows = Math.min(rowsInDB, rowsInDB + 10); //here we get 5 Set randomIndexes = []; while (randomIndexes.size() \u003c buffer) { randomIndexes.add(random.nextInt(minRows)); //seed is 5 } The Set will not increase its size because it accepts unique values that are always between 0-4. Set can contain only 0,1,2,3,4. The size of the set will not increase more than 5 where the buffer is always 10 - infinite loop detected.\nWrote a unit test, confirmed the bug, fixed the test, made a hotfix.\nüìö Userfull links How to get thread id and stack IBM best practices Top -H Fastthread.io\n","wordCount":"754","inLanguage":"en","datePublished":"2022-07-01T17:02:01+03:00","dateModified":"2022-07-01T17:02:01+03:00","author":{"@type":"Person","name":"dcebotarenco"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://dcebotarenco.github.io/posts/high-cpu-usage-while-loop/"},"publisher":{"@type":"Organization","name":"dcebotarenco","logo":{"@type":"ImageObject","url":"https://dcebotarenco.github.io/icon.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://dcebotarenco.github.io/ accesskey=h title="dcebotarenco (Alt + H)"><img src=https://dcebotarenco.github.io/icon.png alt aria-label=logo height=35>dcebotarenco</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://dcebotarenco.github.io/about/ title=About><span>About</span></a></li><li><a href=https://dcebotarenco.github.io/posts/ title=Blog><span>Blog</span></a></li><li><a href=https://dcebotarenco.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://dcebotarenco.github.io/>Home</a>&nbsp;¬ª&nbsp;<a href=https://dcebotarenco.github.io/posts/>Posts</a></div><h1 class=post-title>üî• High CPU usage on faulty endpoint</h1><div class=post-meta><span title='2022-07-01 17:02:01 +0300 +0300'>July 1, 2022</span>&nbsp;¬∑&nbsp;4 min&nbsp;¬∑&nbsp;754 words&nbsp;¬∑&nbsp;dcebotarenco</div></header><div class=post-content><h1 id=-tltr>üßë‚Äçüéì tltr<a hidden class=anchor aria-hidden=true href=#-tltr>#</a></h1><p>Infinite while loop was causing the issue. Write unit tests. Test the exit condition of your while loops.</p><h1 id=-issue>üêõ Issue<a hidden class=anchor aria-hidden=true href=#-issue>#</a></h1><p>We had some kind of serious performance issue on production. The CPU periodically was pegged at 100% and stayed that way until we restarted the <a href=https://tomcat.apache.org>Tomcat</a>. It was degrading the overall site performance for quite a while. We had two instances with peak similarly in CPU. Seems like it must be something inside the Tomcat since that&rsquo;s what is eating the CPU.</p><p><strong>Here is the 6-week view:</strong>
<img loading=lazy src=images/cpu-utilization.jpeg alt="6-week CPU utilization"></p><p><strong>Here is the 12-week view:</strong>
<img loading=lazy src=images/year-cpu-usage.jpeg alt="12-week CPU utilization"></p><p>The immediate fall of the CPU is where we restart the Tomcat.<br>As you see, after the restart, the CPU jumps back on the ladder ü™ú in a couple of days.</p><h1 id=-investigation>üïµÔ∏è‚Äç‚ôÇÔ∏è Investigation<a hidden class=anchor aria-hidden=true href=#-investigation>#</a></h1><h3 id=1-thread-dump--top--h>1. Thread dump & top -H<a hidden class=anchor aria-hidden=true href=#1-thread-dump--top--h>#</a></h3><p>On Linux, the <code>top -h &lt;pid></code> is useful to determine the overall usage by all processes and break it down to certain threads within a process.
Our <a href=https://en.wikipedia.org/wiki/Process_identifier>PID</a>:
<img loading=lazy src=images/top-h.png alt="top -h"></p><p>Run <code>kill 3 &lt;pid></code> on the main PID that&rsquo;s consuming a lot of CPU. This will give you the thread dump. It does not stop the running process, but it stops the world inside the JVM.</p><p>What we see is <strong>596</strong> of CPU%. This is related to the number of cores attached to the machine. One core is 100%<br>Convert the PID from <code>top -H</code> from decimal to hex and match it with the <code>nid</code> from the thread dump.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>6458 -&gt; nid=0x1936 
</span></span></code></pre></div><p>Not the ideal way to monitor a JVM instance. You should prefer agents like <a href=https://sematext.com/docs/agents/sematext-agent/>Sematext</a>, <a href=https://www.ej-technologies.com/download/jprofiler/files>JProfiler</a>, <a href=https://www.yourkit.com/java/profiler/purchase/>YourKit</a> or <a href=https://access.redhat.com/solutions/662203>JFR</a>. But we have what we have üëâ</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>&#34;http-nio-8080-exec-127&#34; #328 daemon prio=5 os_prio=0 tid=0x00007f9f20020000 lwp=6454 nid=0x1936 runnable [0x00007f9e4ada4000]
</span></span><span class=line><span class=cl>   java.lang.Thread.State: RUNNABLE
</span></span><span class=line><span class=cl>    at java.util.HashMap.hash(HashMap.java:339)
</span></span><span class=line><span class=cl>    at java.util.HashMap.put(HashMap.java:612)
</span></span><span class=line><span class=cl>    at java.util.HashSet.add(HashSet.java:220)
</span></span><span class=line><span class=cl>    at java_util_Set$add$0.call(Unknown Source)
</span></span><span class=line><span class=cl>    at com.site.api.Controller.method(Controller.groovy:95)
</span></span><span class=line><span class=cl>    at com.site.api.Controller.method(Controller.groovy)
</span></span><span class=line><span class=cl>&#34;http-nio-8080-exec-156&#34; #39893 daemon prio=5 os_prio=0 tid=0x00007f9f20024000 lwp=18378 nid=0x47ca runnable [0x00007f9e3199e000]
</span></span><span class=line><span class=cl>   java.lang.Thread.State: RUNNABLE
</span></span><span class=line><span class=cl>    at java.util.HashMap.hash(HashMap.java:339)
</span></span><span class=line><span class=cl>    at java.util.HashMap.put(HashMap.java:612)
</span></span><span class=line><span class=cl>    at java.util.HashSet.add(HashSet.java:220)
</span></span><span class=line><span class=cl>    at java_util_Set$add$0.call(Unknown Source)
</span></span><span class=line><span class=cl>    at com.site.api.Controller.method(Controller.groovy:95)
</span></span><span class=line><span class=cl>    at com.site.api.Controller.method(Controller.groovy)
</span></span><span class=line><span class=cl>&#34;http-nio-8080-exec-95&#34; #203 daemon prio=5 os_prio=0 tid=0x00007f9f200a9000 lwp=5605 nid=0x15e5 runnable [0x00007f9e48d82000]
</span></span><span class=line><span class=cl>   java.lang.Thread.State: RUNNABLE
</span></span><span class=line><span class=cl>    at com.site.api.Controller.method(Controller.groovy:95)
</span></span><span class=line><span class=cl>    at com.site.api.Controller.method(Controller.groovy)
</span></span><span class=line><span class=cl>    at com.site.api.Controller$$FastClassBySpringCGLIB$$8fdc140f.invoke(&lt;generated&gt;)
</span></span><span class=line><span class=cl>    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
</span></span><span class=line><span class=cl>    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:752)
</span></span><span class=line><span class=cl>    at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
</span></span><span class=line><span class=cl>&#34;http-nio-8080-exec-120&#34; #321 daemon prio=5 os_prio=0 tid=0x00007f9f20036800 lwp=6351 nid=0x18cf runnable [0x00007f9e4cec3000]
</span></span><span class=line><span class=cl>   java.lang.Thread.State: RUNNABLE
</span></span><span class=line><span class=cl>    at java_util_Set$add$0.call(Unknown Source)
</span></span><span class=line><span class=cl>    at com.site.api.Controller.method(Controller.groovy:95)
</span></span><span class=line><span class=cl>    at com.site.api.Controller.method(Controller.groovy)
</span></span><span class=line><span class=cl>    at com.site.api.Controller$$FastClassBySpringCGLIB$$8fdc140f.invoke(&lt;generated&gt;)
</span></span><span class=line><span class=cl>    at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218)
</span></span><span class=line><span class=cl>    at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:752)
</span></span></code></pre></div><h3 id=2-traffic>2. Traffic<a hidden class=anchor aria-hidden=true href=#2-traffic>#</a></h3><p>I analyzed the traffic at the point of time where the CPU jumps. I got some <strong>httpd</strong> logs.<br><strong>httpd</strong> is in front of Tomcat for <a href=https://www.perimeterx.com>PerimeterX</a> compatibility.<br>Example of logs:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>87.250.224.200 - - [06/Jun/2022:21:17:08 +0000] &#34;GET /the-faulty-endpoint/id-1 HTTP/1.1&#34; 502 341 &#34;https://www.site.com/pages/page-1&#34; &#34;Mozilla/5.0 (compatible; YandexBot/3.0; +http://yandex.com/bots) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.268&#34; 120120565
</span></span><span class=line><span class=cl>85.45.207.139 - - [06/Jun/2022:21:18:08 +0000] &#34;GET /the-faulty-endpoint/id-2 HTTP/1.1&#34; 502 341 &#34;https://www.site.com/pages/page-1&#34; &#34;Mozilla/5.0 (compatible; YandexBot/3.0; +http://yandex.com/bots) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/81.0.4044.268&#34; 120122901
</span></span></code></pre></div><p>At that point in point in time, I saw just a lot of bots (Apple, Google, Yandex, Bing) indexing the pages</p><h2 id=-put-things-together>‚úÖ Put things together<a hidden class=anchor aria-hidden=true href=#-put-things-together>#</a></h2><p>What we have now is the requests which tell us the URLs that are called and the values in a URLs.<br>The values in the paths are different <code>id-1</code>, <code>id-2</code>, <code>id-n</code>.<br>We also have the code, which we can analyze locally. Code has no tests üòí</p><p>Simplified pseudo-code:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=kt>int</span> <span class=n>rowsInDB</span> <span class=o>=</span> <span class=n>findBy</span><span class=o>(</span><span class=err>&#39;</span><span class=n>id</span><span class=o>-</span><span class=n>from</span><span class=o>-</span><span class=n>url</span><span class=err>&#39;</span><span class=o>);</span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=n>buffer</span> <span class=o>=</span> <span class=n>10</span><span class=o>;</span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=n>minRows</span> <span class=o>=</span> <span class=n>Math</span><span class=o>.</span><span class=na>min</span><span class=o>(</span><span class=n>rowsInDB</span><span class=o>,</span> <span class=n>rowsInDB</span> <span class=o>+</span> <span class=n>10</span><span class=o>);</span>
</span></span><span class=line><span class=cl><span class=n>Set</span> <span class=n>randomIndexes</span> <span class=o>=</span> <span class=o>[];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>while</span> <span class=o>(</span><span class=n>randomIndexes</span><span class=o>.</span><span class=na>size</span><span class=o>()</span> <span class=o>&lt;</span> <span class=n>buffer</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>   <span class=n>randomIndexes</span><span class=o>.</span><span class=na>add</span><span class=o>(</span><span class=n>random</span><span class=o>.</span><span class=na>nextInt</span><span class=o>(</span><span class=n>minRows</span><span class=o>));</span>
</span></span><span class=line><span class=cl><span class=o>}</span>
</span></span></code></pre></div><p>At first, I could not spot the bug because I was on the local environment with no data in my H2 database.</p><p>I assembled a list of all the requests within CPU increase timeframe into a CSV file.<br>Launched locally the JMeter, VisualVM, JDK Mission Control and the app connected to the QA database with data and fired all the requests to my local instance. Finally, I noticed locally a CPU increase, which is not going down.</p><p>There was an <code>id</code> that returned <code>5</code> rows from the database. Then I realized that the problem is related to the <code>random.nextInt(minRows)</code> and the Set collection. Here is why:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-java data-lang=java><span class=line><span class=cl><span class=kt>int</span> <span class=n>rowsInDB</span> <span class=o>=</span> <span class=n>findBy</span><span class=o>(</span><span class=err>&#39;</span><span class=n>faulty</span><span class=o>-</span><span class=n>id</span><span class=err>&#39;</span><span class=o>);</span> <span class=c1>//returns 5
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=kt>int</span> <span class=n>buffer</span> <span class=o>=</span> <span class=n>10</span><span class=o>;</span>
</span></span><span class=line><span class=cl><span class=kt>int</span> <span class=n>minRows</span> <span class=o>=</span> <span class=n>Math</span><span class=o>.</span><span class=na>min</span><span class=o>(</span><span class=n>rowsInDB</span><span class=o>,</span> <span class=n>rowsInDB</span> <span class=o>+</span> <span class=n>10</span><span class=o>);</span> <span class=c1>//here we get 5
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=n>Set</span> <span class=n>randomIndexes</span> <span class=o>=</span> <span class=o>[];</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>while</span> <span class=o>(</span><span class=n>randomIndexes</span><span class=o>.</span><span class=na>size</span><span class=o>()</span> <span class=o>&lt;</span> <span class=n>buffer</span><span class=o>)</span> <span class=o>{</span>
</span></span><span class=line><span class=cl>   <span class=n>randomIndexes</span><span class=o>.</span><span class=na>add</span><span class=o>(</span><span class=n>random</span><span class=o>.</span><span class=na>nextInt</span><span class=o>(</span><span class=n>minRows</span><span class=o>));</span> <span class=c1>//seed is 5
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=o>}</span>
</span></span></code></pre></div><p>The Set will not increase its size because it accepts unique values that are always between <code>0-4</code>. Set can contain only <code>0,1,2,3,4</code>. The size of the set will not increase more than <code>5</code> where the buffer is always <code>10</code> - infinite loop detected.</p><p><img loading=lazy src=images/bug-demonstration.jpeg alt="Demo screenshot"></p><p>Wrote a unit test, confirmed the bug, fixed the test, made a hotfix.</p><h1 id=-userfull-links>üìö Userfull links<a hidden class=anchor aria-hidden=true href=#-userfull-links>#</a></h1><p><a href=https://stackoverflow.com/questions/222108/getting-the-java-thread-id-and-stack-trace-of-run-away-java-thread>How to get thread id and stack</a><br><a href="https://www.ibm.com/docs/en/baw/19.x?topic=issues-best-practices-high-jvm-cpu-utilization">IBM best practices</a><br><a href=https://backstage.forgerock.com/knowledge/kb/article/a48313100>Top -H</a><br><a href=https://fastthread.io/>Fastthread.io</a></p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=prev href=https://dcebotarenco.github.io/posts/stream-api-question/><span class=title>¬´ Prev</span><br><span>ü™§ Peek & Filter Stream API</span></a>
<a class=next href=https://dcebotarenco.github.io/posts/reactor-connection-pool/><span class=title>Next ¬ª</span><br><span>üçÉ Spring WebClient & Connection Pool</span></a></nav><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share üî• High CPU usage on faulty endpoint on twitter" href="https://twitter.com/intent/tweet/?text=%f0%9f%94%a5%20High%20CPU%20usage%20on%20faulty%20endpoint&url=https%3a%2f%2fdcebotarenco.github.io%2fposts%2fhigh-cpu-usage-while-loop%2f&hashtags="><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM195.519 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share üî• High CPU usage on faulty endpoint on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fdcebotarenco.github.io%2fposts%2fhigh-cpu-usage-while-loop%2f&title=%f0%9f%94%a5%20High%20CPU%20usage%20on%20faulty%20endpoint&summary=%f0%9f%94%a5%20High%20CPU%20usage%20on%20faulty%20endpoint&source=https%3a%2f%2fdcebotarenco.github.io%2fposts%2fhigh-cpu-usage-while-loop%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share üî• High CPU usage on faulty endpoint on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fdcebotarenco.github.io%2fposts%2fhigh-cpu-usage-while-loop%2f&title=%f0%9f%94%a5%20High%20CPU%20usage%20on%20faulty%20endpoint"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share üî• High CPU usage on faulty endpoint on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fdcebotarenco.github.io%2fposts%2fhigh-cpu-usage-while-loop%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share üî• High CPU usage on faulty endpoint on whatsapp" href="https://api.whatsapp.com/send?text=%f0%9f%94%a5%20High%20CPU%20usage%20on%20faulty%20endpoint%20-%20https%3a%2f%2fdcebotarenco.github.io%2fposts%2fhigh-cpu-usage-while-loop%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentcolor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share üî• High CPU usage on faulty endpoint on telegram" href="https://telegram.me/share/url?text=%f0%9f%94%a5%20High%20CPU%20usage%20on%20faulty%20endpoint&url=https%3a%2f%2fdcebotarenco.github.io%2fposts%2fhigh-cpu-usage-while-loop%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentcolor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer><div id=disqus_thread></div><script type=application/javascript>window.disqus_config=function(){},function(){if(["localhost","127.0.0.1"].indexOf(window.location.hostname)!=-1){document.getElementById("disqus_thread").innerHTML="Disqus comments not available by default when the website is previewed locally.";return}var t=document,e=t.createElement("script");e.async=!0,e.src="//dcebotarenco-github-io.disqus.com/embed.js",e.setAttribute("data-timestamp",+new Date),(t.head||t.body).appendChild(e)}()</script><noscript>Please enable JavaScript to view the <a href=https://disqus.com/?ref_noscript>comments powered by Disqus.</a></noscript><a href=https://disqus.com class=dsq-brlink>comments powered by <span class=logo-disqus>Disqus</span></a></article></main><footer class=footer><span>&copy; 2022 <a href=https://dcebotarenco.github.io/>dcebotarenco</a></span>
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
        <a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>